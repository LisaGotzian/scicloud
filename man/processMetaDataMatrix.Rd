% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/3_processMetaDataMatrix.R
\name{processMetaDataMatrix}
\alias{processMetaDataMatrix}
\title{processMetaDataMatrix}
\usage{
processMetaDataMatrix(
  metaMatrix,
  control = list(),
  ignoreWords = c(),
  keepWordsFile = NA
)
}
\arguments{
\item{metaMatrix}{metaMatrix created through \code{\link{getScopusMetaData}}
or \code{\link{createTextMatrixFromPDF}}. Equations, symbols, all words
in parentheses and all references are removed.}

\item{control}{a list of parameters used to determine preprocessing methods.
Error will be thrown if language & stemWords are not defined.\cr
\strong{language}: this defines the stopwords to be filtered. the default is
"english". Look at \code{\link[tm]{stopwords}} for more information.\cr
\strong{stemWords}: can be \code{TRUE} of \code{FALSE}. Transforms every word
to its stem, so variants of the same words are treated equally. Look
at \code{\link[tm]{stemDocument}} for more information.\cr
\strong{saveToWd}: a logical parameter whether or not to save the output of the
function to the working directory. This is especially useful for later
analysis steps. The file can be read in by using \code{\link[base]{readRDS}}.\cr
e.g. control = list(language = "SMART", stemWords = FALSE, saveToWd = TRUE)}

\item{ignoreWords}{a vector of words to be ignored.}

\item{keepWordsFile}{path to a .csv-file that specifies which words to keep
during the analysis. Accepts 0/1 behind each word or takes the words
as they are and disregards all other words of the analysis. A template
for this can be generated with \code{generateWordlist} in
\code{\link{ordinationCluster}} or \code{\link{calculateModels}}.}
}
\value{
returns a list object with \code{[["Tf_idf"]]} as the tf-idf document
    term matrix, \code{[["metaMatrix"]]} as passed to the function and
\code{[["wordList"]]} is the list of all words found in the papers.
}
\description{
The third function to the word analysis with scicloud. This function
    accepts a \code{metaMatrix} filled with metadata and constructs a tf-idf matrix.
}
\examples{
\dontrun{

### The normal workflow of scicloud
myAPIKey <- "YOUR_API_KEY"
metaMatrix <- createTextMatrixFromPDF()


# instead of ordinationCluster(), we can also run this
# workflow step by step.

# 1) pull article metadata from scopus
metaMatrix <- getScopusMetaData(metaMatrix, myAPIKey)

# 2) process the full texts
processedMetaDataMatrix <- processMetaDataMatrix(
          metaMatrix,
          list(language = "SMART",
          stemWords = TRUE,
          saveToWd = FALSE),
          ignoreWords = c("Abstract", "Bulletin", "Editor"))
                                  
# 3) run the cluster analysis to determine publication communities
scicloudAnalysis <- calculateModels(processedMetaDataMatrix)

# 4) visualize the results
createOrdinationPlot(scicloudAnalysis)

# 5) a list of the most important papers per cluster
mostImportantPaperPerCluster(scicloudAnalysis)

# 6) a summary of the analysis
scicloudSpecs <- inspectScicloud(scicloudAnalysis)

}
}
\seealso{
\itemize{
    \item \code{\link{createTextMatrixFromPDF}} and \code{\link{getScopusMetaData}}
    for the preceding steps
    \item \code{\link{calculateModels}} for the proceeding step
    }

Other scicloud functions: 
\code{\link{calculateModels}()},
\code{\link{createOrdinationPlot}()},
\code{\link{createTextMatrixFromPDF}()},
\code{\link{delete_RDS}()},
\code{\link{getScopusMetaData}()},
\code{\link{inspectScicloud}()},
\code{\link{mostImportantPaperPerCluster}()},
\code{\link{ordinationCluster}()},
\code{\link{rename_PDFs}()},
\code{\link{searchScopus}()}
}
\author{
Jia Yan Ng, \email{jia.y.ng@stud.leuphana.de}
}
\concept{scicloud functions}
